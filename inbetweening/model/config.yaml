trainer:
  max_epochs: 50000 ## TODO: Adapt
  precision: 32

data:
  data_dir: /proj/diffusion-inbetweening/data
  batch_size: 256
  window: &window_val 50
  offset: 20
  
model:
  lr: 0.0001
  beta_start: 0.0001 
  beta_end: 0.02
  n_diffusion_timesteps: 1000
  gap_size: 15 # Set this to the gap size I want to have at the beginning of the training (1 for the first time, higher if we start from a checkpoint)
  type_masking: 'continued' # Options are continued or spread
  time_emb_dim: 32
  window: *window_val
  n_joints: 22 ## Hardcoded according to the dataset
  type_model: 'unet'
  down_channels: [256, 512, 1024] ## THE NUMBER OF CHANNELS IN THE UNET SHOULD INCREASE IN THE DOWN BRANCH, AND INCREASE IN THE UP BRANCH
  kernel_size: 5
  step_threshold: 12000 ## TODO: Adapt
  max_gap_size: 30